global: 
  pattern: amdllm

  amdllm:
    namespace: amd-llm
    build_envs: [] # http_proxy/https_prxy can be set here
    runtime_envs: []

    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.6
    main_service_name: tei-service

    deployments:
      - name: tei-reranker
        service_name: tei-reranker-service
        service_port: 5006
        container_port: 8080
        model: BAAI/bge-reranker-base
        truncate: true

      - name: tei-embedding
        service_name: tei-embedding-service
        service_port: 5007
        container_port: 8080
        model: BAAI/bge-base-en-v1.5
        truncate: false

    pvc:
      size: 3Gi

    secret:
      env_name: HF_TOKEN
      name: hf-token-secret
      key: huggingface

